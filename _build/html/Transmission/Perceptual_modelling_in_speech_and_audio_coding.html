
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Perceptual modelling in speech and audio coding &#8212; Introduction to Speech Processing</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Introduction to Speech Processing</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   Introduction to Speech Processing
  </a>
 </li>
</ul>
    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Transmission/Perceptual_modelling_in_speech_and_audio_coding.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#frequency-masking">
   Frequency masking
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#frequency-scale">
   Frequency scale
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#temporal-masking">
   Temporal masking
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Perceptual modelling in speech and audio coding</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#frequency-masking">
   Frequency masking
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#frequency-scale">
   Frequency scale
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#temporal-masking">
   Temporal masking
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="perceptual-modelling-in-speech-and-audio-coding">
<h1>Perceptual modelling in speech and audio coding<a class="headerlink" href="#perceptual-modelling-in-speech-and-audio-coding" title="Permalink to this headline">¶</a></h1>
<div class="contentLayout2">
<div class="columnLayout two-equal" layout="two-equal">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p>Humans are usually the intended recipients of speech signals in
telecommunication, such that the quality of a transmission should be
measured in terms of how good a human listener would judge its quality.
<em>Perceptual models</em> refer to methods which try to approximate or predict
the judgement of auditory quality perceived by human listeners. In
coding applications we can thus define perceptual models as <em>evaluation
models</em>, with which we approximate the perceptual effect of distortions.</p>
<p>An another type of models which are frequently used in speech coding are
<em>source models</em>, which describe the inherent characteristics of the
source, which is the speech signal. You can think of a source model as
for example 1) physical models, which describe the physiological
processes which cause speech sounds or 2) the probability distribution
of speech signals. The important distinction is that source models do
not care about who is observing, but they only describe the objective
reality. In contrast, perceptual models are applied when <em>we
subjectively observe</em> the signal, to evaluate properties of the signal.</p>
<p>In speech and audio coding applications, practically all distortions
caused by the algorithms are due to quantization of the signal. The
objective of perceptual modelling is then to choose the quantization
accuracy such that the perceptually degrading effect of quantization is
minimized. Roughly speaking, this means that those signal components
which are more important to a human listener are quantized with a higher
accuracy than those which are less important.</p>
</div>
</div>
<div class="cell normal" data-type="normal">
<div class="innerCell">
</div>
</div>
</div>
<div class="columnLayout two-equal" layout="two-equal">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<div class="section" id="frequency-masking">
<h2>Frequency masking<a class="headerlink" href="#frequency-masking" title="Permalink to this headline">¶</a></h2>
<p>If we play two sinusoid with slightly different frequencies, then the
louder of the two can <em>mask</em> the second sinusoid such that it becomes
inaudible. This effect is known as <em>frequency masking</em>. In other words,
people are less sensitive to sounds which are near in frequency to other
sounds. In particular, when quantizing a signal, we can use a lower
quantization accuracy in frequency-regions which have more energy. The
effect is reduced the further away we are in frequency.</p>
<p>In practice, frequency masking models are similar to spectral (energy)
envelopes. That is, the shape of the frequency masking model is similar
to the spectral envelope, but a smoothed and less pronounced version
thereof. More accurate versions of the model can be generated based on
<a class="reference external" href="https://en.wikipedia.org/wiki/Psychoacoustics">psychoacoustic</a> theory.</p>
<p>Frequency masking models are used in two ways:</p>
<ul class="simple">
<li><p>In frequency-domain codecs, where a frequency-domain representation
of the signal is quantized, we choose the quantization accuracy in
different regions of the spectrum based on a perceptual model.
Typically high-energy regions are quantized with less accuracy than
low-energy regions.</p></li>
<li><p>In time-domain codecs such as CELP, we typically use a
analysis-by-synthesis loop, where different quantized versions are
synthesized and the error between original and quantized signal is
determined with perceptual weighting. The weighting is here based on
a frequency masking model. Out of the different possible
quantizations, the one with the smallest perceptually weighted error
is chosen.</p></li>
</ul>
</div>
</div>
<div class="cell normal" data-type="normal">
<div class="innerCell">
</div>
</div>
</div>
<div class="columnLayout two-equal" layout="two-equal">
<div class="cell normal" data-type="normal">
<div class="innerCell">
</div>
<div class="section" id="frequency-scale">
<h2>Frequency scale<a class="headerlink" href="#frequency-scale" title="Permalink to this headline">¶</a></h2>
<p>The sensitivity of human hearing depends on the frequency range where
the sound is present. We are more sensitive in the “low” regions and
less sensitive at “high” frequencies. There is however some ambiguity in
how sensitivity is defined, and we have two prominent different
interpretations:</p>
<ul class="simple">
<li><p>In the cochlea of the human ear, sounds are processed in spectral
bands, which are independent such that sounds in separate bands do
not interfere with each other, but sounds within the same band <em>do
interfere</em> with the perception of each other. This is known as
auditory masking. The width of these bands is frequency dependent
and increases with increasing frequency. This aspect of perception
has been approximated with several models, including the
<a class="reference external" href="https://en.wikipedia.org/wiki/Bark_scale">Bark</a> and
<a class="reference external" href="https://en.wikipedia.org/wiki/Equivalent_rectangular_bandwidth">ERB</a>
scales.</p></li>
<li><p>The distance between pitches are perceived differently depending on
their frequencies. In short, a perceptually small step in pitch
(measured in frequencies) is much larger at higher frequencies than
at low frequencies. This aspect of perception can be approximated
with the <a class="reference external" href="https://en.wikipedia.org/wiki/Mel_scale">Mel scale</a>.</p></li>
</ul>
</div>
</div>
<div class="cell normal" data-type="normal">
<div class="innerCell">
</div>
</div>
</div>
<div class="columnLayout two-equal" layout="two-equal">
<div class="cell normal" data-type="normal">
<div class="innerCell">
</div>
<div class="section" id="temporal-masking">
<h2>Temporal masking<a class="headerlink" href="#temporal-masking" title="Permalink to this headline">¶</a></h2>
<p>The variation in accuracy and sensitivity of perception is interesting
also across time. In particular, a loud sound can make imperceptible a
second, weaker sound which comes later in time. Say, if we have two
impulses, consecutive in time, and such that the second one is weaker,
and their distance in time is sufficiently short, then we cannot hear
the second impulse. Surprisingly, such temporal masking can occur also
the other way around, a <em>later</em> loud sound can mask a preceding weaker
sound.</p>
</div>
</div>
<div class="cell normal" data-type="normal">
<div class="innerCell">
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Transmission"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Tom Bäckström, Okko Räsänen, Abraham Zewoudie, Pablo Pérez Zarazaga, Liisa Koivusalo, Sneha Das<br/>
    
      <div class="extra_footer">
        <p>
<img src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" style="border-width: 0;" alt="Creative Commons License" />
This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
</p>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>